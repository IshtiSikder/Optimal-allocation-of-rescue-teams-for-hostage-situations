{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmBs2W2LnSNtkCKiUx6N4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshtiSikder/Optimal-allocation-of-rescue-teams-for-hostage-situations/blob/final/R_for_MDP_(NEW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "SuGR5I-e1Z-J",
        "outputId": "de8c9ca7-ab93-4a0e-b9ab-5cf96e3d6a13"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in parse(text = x, srcfile = src): <text>:236:3: unexpected string constant\n252:   geom_line(size=1) +\n253:   labs(x = '\n       ^\nTraceback:\n"
          ]
        }
      ],
      "source": [
        "# CTMC MDP model for rescue operational system!!!\n",
        "# For steady state prob for optimal policy\n",
        "prob <- function(opSet = policySet, t, lam, eps, mu) {\n",
        "  opTRM = matrix(0, nrow = t+1, ncol = t+1)\n",
        "  for (i in 2:t) {\n",
        "    opTRM[i, i-1] = sum(i*eps, opSet[i]*mu)\n",
        "    opTRM[i, i+1] = lam      \n",
        "  }\n",
        "  opTRM[1, 2] = lam\n",
        "  opTRM[t+1, t] = sum(t*eps, opSet[t+1]*mu)\n",
        "  \n",
        "  k = t+1\n",
        "  steady_prob <- matrix(0, nrow=1, ncol=k)\n",
        "  state <- matrix(0, nrow=1, ncol=k-1)\n",
        "  for (i in 1:(k-1)) {\n",
        "    if (i-2 < 0) {\n",
        "      state[i] <- (lam/opTRM[i+1,i])\n",
        "    } else {\n",
        "      state[i] <- state[i-1]*(lam/opTRM[i+1,i])\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  steady_prob[1] <- (1+sum(state))^-1\n",
        "  for (i in 2:k) {\n",
        "    steady_prob[i] <- state[i-1]*steady_prob[1]\n",
        "  }\n",
        "  return(steady_prob)\n",
        "}\n",
        "\n",
        "# Check function to determine new policy is same with current or not \n",
        "checkPolicy = function(policySet, policySetnew) {\n",
        "  n = 0\n",
        "  for (i in policySet == policySetnew) {\n",
        "    if (i == 'FALSE') {\n",
        "      n = 1\n",
        "    } \n",
        "  } \n",
        "  if (n == 0) {\n",
        "    return(\"TRUE\")\n",
        "  } else {\n",
        "    return(\"FALSE\")\n",
        "  }\n",
        "} \n",
        "\n",
        "rewardR <- function(costR, RC, nr) {\n",
        "  if (RC == \"SR\") {\n",
        "    if (costR < 0) {\n",
        "      result = -sqrt(-costR * nr)      \n",
        "    } else {\n",
        "      result = sqrt(costR * nr)\n",
        "    }\n",
        "  } else if (RC == \"L\") {\n",
        "    result = costR * nr      \n",
        "  } else {\n",
        "    if (costR < 0) {\n",
        "      result = -(costR * nr)^2      \n",
        "    } else {\n",
        "      result = (costR * nr)^2      \n",
        "    }\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "\n",
        "rewardT <- function(costT, TC, nt) {\n",
        "  if (TC == \"SR\") {\n",
        "    if (costT < 0) {\n",
        "      result = -sqrt(-costT * nt)      \n",
        "    } else {\n",
        "      result = sqrt(costT * nt)\n",
        "    }\n",
        "  } else if (TC == \"L\") {\n",
        "    result = costT * nt      \n",
        "  } else {\n",
        "    if (costT < 0) {\n",
        "      result = -(costT * nt)^2      \n",
        "    } else {\n",
        "      result = (costT * nt)^2      \n",
        "    }\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "\n",
        "#########################################################\n",
        "#EDITS: 22ND FEB,2023\n",
        "#NEW SERVICE RATE STRUCTURE. ADD ORIGINAL ONE AS WELL\n",
        "probR = function(nr, nt, eps, mu, SR) {\n",
        "  #if (nt == 0 & nr == 0) {\n",
        "  if (nt == 0){\n",
        "    result = 0\n",
        "  } else {\n",
        "    if(SR=='ORG'){\n",
        "      result = nr*mu / (nr*mu + nt*eps)\n",
        "    }\n",
        "    else {\n",
        "    result = min(nr,nt)*mu / (min(nr,nt)*mu + nt*eps)\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "#########################################################\n",
        "\n",
        "# Define MDP function (for basic policy)\n",
        "MDP = function(lam, mu, eps, numRescue, numTerror, costR, costT, RC, TC, SR) {\n",
        "  r = numRescue\n",
        "  t = numTerror\n",
        "  # Design the three dimension matrix(i,j,k)\n",
        "  # k: Index of rescue team\n",
        "  # i: state(current)\n",
        "  # j: state(next)\n",
        "  \n",
        "  \n",
        "  #########################################################\n",
        "  #EDITS: 22ND FEB,2023\n",
        "  #NEW SERVICE RATES STRUCTURE, ADD ORIGINAL ONE AS WELL\n",
        "  aijMatrix = array(0, dim = c(t+1,t+1,r+1))\n",
        "  for (k in 1:(r+1)) {\n",
        "    for (i in 1:t) {\n",
        "      aijMatrix[i,i+1,k] <- lam\n",
        "      if (i > 1) {\n",
        "        if (SR=='ORG'){\n",
        "          aijMatrix[i,i-1,k] <- sum((k-1)*mu+(i-1)*eps)\n",
        "            }\n",
        "          else{ \n",
        "        aijMatrix[i,i-1,k] <- sum(min(k-1,i-1)*mu+(i-1)*eps)        \n",
        "      }\n",
        "    }\n",
        "    if (SR=='ORG'){\n",
        "      aijMatrix[t+1,t,k] <- ((k-1)*mu+t*eps)\n",
        "    }\n",
        "    else {\n",
        "      aijMatrix[t+1,t,k] <- (min(k-1,t)*mu+t*eps)\n",
        "    }\n",
        "    #aijMatrix[1,2,k] <- lam\n",
        "}\n",
        "\n",
        "  for (k in 1:(r+1)) {\n",
        "    for (i in 1:(t+1)) {\n",
        "      \n",
        "      aijMatrix[i,i,k] <- -sum(aijMatrix[i,,k])      \n",
        "    }\n",
        "  }\n",
        "  #########################################################\n",
        "  \n",
        "  #print(aijMatrix[4,4,5])\n",
        "  #cat('meu',mu)\n",
        "  #cat('epsilon',eps)\n",
        "  #break\n",
        "  \n",
        "  \n",
        "  # Design the MDP algorithm\n",
        "  # Value determination\n",
        "  policy = array(0, dim = c(1,t+1)) \n",
        "  policyOld = array(0, dim = c(1,t+1))\n",
        "  policyNew = array(2, dim=c(1,t+1)) # initially set all decision is 1 in first policy\n",
        "  policyTrack = array(2, dim=c(1,t+1))\n",
        "  iteration = 0\n",
        "  gainMatrix = c()\n",
        "  \n",
        "  while (checkPolicy(policyOld, policyNew) == 'FALSE') {\n",
        "    policyOld = policyNew\n",
        "    policy = policyNew\n",
        "    # Design the transition matrix regarding policy\n",
        "    A = array(0, dim = c(t+1,t+1))\n",
        "    for (i in 1:length(policy)) {\n",
        "      A[i,] = aijMatrix[i,,(policy[i])]  \n",
        "    }\n",
        "\n",
        "    # Design the cost matrix regarding policy\n",
        "    q = array(0, dim = c(t+1,1))\n",
        "    for (i in 1:length(policy)) {\n",
        "      cost = probR(nr=(policy[i]-1),nt=(i-1),eps,mu)*rewardR(costR, RC, nr=(policy[i]-1))+\n",
        "        (1-probR(nr=(policy[i]-1),nt=(i-1),eps,mu))*rewardT(costT, TC, nt=(i-1))\n",
        "      q[i,1] = cost\n",
        "    }\n",
        "    newA = cbind(array(1, dim=c(t+1,1)), -A[,1:t])\n",
        "    solution = solve(newA) %*% q\n",
        "    gain = solution[1] # First row of solution is gain value\n",
        "    gainMatrix = append(gainMatrix, gain)\n",
        "    \n",
        "    # Policy improvement\n",
        "    newsolution = array(0, dim=c(t+1,1))\n",
        "    for (i in 1:t) {\n",
        "      newsolution[i] = solution[i+1]\n",
        "    }\n",
        "    newsolution[t+1] = 0 # Set last v value as 0 to calcultate the test quantity in policy improvement\n",
        "    improveMatrix = array(0, dim=c(t+1,r+1))\n",
        "    for (i in 1:(t+1)) {\n",
        "      for (j in 1:(r+1)) {\n",
        "        # Cost when we have j rescue operation and i terrorists\n",
        "        cost = probR(nr=(j-1),nt=(i-1),eps,mu)*rewardR(costR, RC, nr=(j-1))+\n",
        "          (1-probR(nr=(j-1),nt=(i-1),eps,mu))*rewardT(costT, TC, nt=(i-1))\n",
        "        improveMatrix[i,j] = cost + aijMatrix[i,,j] %*% newsolution\n",
        "      }\n",
        "    }  \n",
        "    \n",
        "    # pick the minimum value among the decision\n",
        "    policyNew = array(1, dim = c(1,t+1))\n",
        "    for (i in 1:length(policyNew)) {\n",
        "      policyNew[i] = which.min(improveMatrix[i,])\n",
        "    }\n",
        "    iteration = iteration + 1\n",
        "    policyTrack = rbind(policyTrack, policyNew)\n",
        "    policyNew\n",
        "  }\n",
        "  for (i in 1:length(policyNew)) {\n",
        "    policyNew[i] = policyNew[i] - 1\n",
        "  }\n",
        "  for (i in 1:nrow(policyTrack)) {\n",
        "    for (j in 1:ncol(policyTrack)) {\n",
        "      policyTrack[i,j] = policyTrack[i,j] - 1      \n",
        "    }\n",
        "\n",
        "  }\n",
        "  stateName = c()\n",
        "  for (i in 1:(t+1)) {\n",
        "    stateName = append(stateName, paste('terror',(i-1)))\n",
        "  }\n",
        "  Steady_prob = prob(opSet = policyNew, t, lam, eps, mu)  \n",
        "  colnames(policyTrack) = stateName\n",
        "  colnames(policyNew) = stateName\n",
        "  colnames(Steady_prob) = stateName\n",
        "  rownames(Steady_prob) = 'Probability'\n",
        "  rownames(policyNew) = 'Decision'\n",
        "  result <- list(\"Iteration\" = iteration,\n",
        "                 \"PolicyChange\" = policyTrack,\n",
        "                 \"Gain\" = gainMatrix,\n",
        "                 \"SteadyStateProb\" = Steady_prob,\n",
        "                 \"Optimal_policy\" = policyNew)\n",
        "  \n",
        "  return(result)\n",
        " \n",
        "}\n",
        "MDP(lam = 0.2763, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=5, costT=1, RC=\"QD\", TC=\"QD\",SR='UP')\n",
        "A = MDP(lam = 0.3546, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=1, costT=1, RC=\"L\", TC=\"L\",SR='UP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1 more iteration for example plot\n",
        "library(ggplot2)\n",
        "result = MDP(lam = 0.2473, mu = 0.2829, eps = 0.1718, numRescue=3, numTerror=5, costR=1, costT=2, RC=\"L\", TC=\"L\",SR=\"UP\")\n",
        "result = result$Gain\n",
        "ddd = array(0, dim=c(5,2))\n",
        "for (i in 1:5) {\n",
        "  ddd[i,1] = i\n",
        "  ddd[i,2] = result[i]  \n",
        "}\n",
        "ddd[5,1] = 5\n",
        "ddd[5,2] = ddd[4,2]\n",
        "\n",
        "ddd = as.data.frame(ddd)\n",
        "ggplot(ddd, aes(x=V1, y=V2)) +\n",
        "  geom_line(size=1) +\n",
        "  labs(x = 'Number of iteration', y = 'Gain value',\n",
        "       title = 'Gain value change during iterations')\n",
        "\n",
        "\n",
        "# Experiment design\n",
        "rescueSet = c(1,2,3,4,5,6,7,8,9,10)\n",
        "gainResult = array(0, dim=c(5,length(rescueSet)))\n",
        "for (j in 1:5) {\n",
        "  for (i in 1:length(rescueSet)) {\n",
        "    val = rescueSet[i]\n",
        "    result = MDP(lam=0.2473, mu=0.2829, eps=0.1718, numRescue=val, numTerror=10, costR=1, costT=j, RC=\"L\", TC=\"L\",SR='UP')\n",
        "    gainResult[j,i] = tail(result$Gain, 1)\n",
        "  }  \n",
        "}\n",
        "gainResult = as.data.frame(t(gainResult))\n",
        "gainResult$index = rescueSet\n",
        "ggplot() +\n",
        "  geom_line(data=gainResult, aes(x=index, y=V1, color='black'), size=1) +\n",
        "  geom_line(data=gainResult, aes(x=index, y=V2, color='red'), size=1) +\n",
        "  geom_line(data=gainResult, aes(x=index, y=V3, color='blue'), size=1) +\n",
        "  geom_line(data=gainResult, aes(x=index, y=V4, color='purple'), size=1) +\n",
        "  geom_line(data=gainResult, aes(x=index, y=V5, color='green'), size=1) +\n",
        "  labs(x = 'Rescue forces capacity', y = 'Gain value of the system',\n",
        "       title = 'Gain of the system over rescue team capacity') +\n",
        "  scale_color_identity(name = \"Terror cost\",\n",
        "                       labels = c(\"cost=1\", \"cost=2\", \"cost=3\", \"cost=4\", \"cost=5\"),\n",
        "                       breaks = c(\"black\", \"red\", \"blue\", \"purple\", \"green\"),\n",
        "                       guide = \"legend\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MDP(lam = 0.2763, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=1, costT=2, RC=\"SR\", TC=\"SR\",SR='UP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "4Jv3qZCcIkQw",
        "outputId": "5ac27791-19af-40b9-9515-bcfec579ec0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in MDP(lam = 0.2763, mu = 0.2829, eps = 0.1718, numRescue = 10, : could not find function \"MDP\"\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aijMatrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "r43HlKFMnT0y",
        "outputId": "9860c66d-9eff-48f0-ad97-0f3d7edba6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in eval(expr, envir, enclos): object 'aijMatrix' not found\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aijMatrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "dw1krX-SnYj5",
        "outputId": "a45e5ab8-61f6-4f8d-ee88-3e2583a4409d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in eval(expr, envir, enclos): object 'aijMatrix' not found\nTraceback:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aijMatrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "LznNMOTUnr4q",
        "outputId": "d0139939-5590-44d8-cf0a-05ade38f9366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in eval(expr, envir, enclos): object 'aijMatrix' not found\nTraceback:\n"
          ]
        }
      ]
    }
  ]
}