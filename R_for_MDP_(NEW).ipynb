{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNulIvpRKYq0DQ20+GlqAz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshtiSikder/Optimal-allocation-of-rescue-teams-for-hostage-situations/blob/final/R_for_MDP_(NEW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "SuGR5I-e1Z-J",
        "outputId": "c4759a95-d19d-4296-87d7-3280345f7a46"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$Iteration</dt>\n",
              "\t\t<dd>3</dd>\n",
              "\t<dt>$PolicyChange</dt>\n",
              "\t\t<dd><table class=\"dataframe\">\n",
              "<caption>A matrix: 4 × 11 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>terror 0</th><th scope=col>terror 1</th><th scope=col>terror 2</th><th scope=col>terror 3</th><th scope=col>terror 4</th><th scope=col>terror 5</th><th scope=col>terror 6</th><th scope=col>terror 7</th><th scope=col>terror 8</th><th scope=col>terror 9</th><th scope=col>terror 10</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td><td>2</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td></tr>\n",
              "\t<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</dd>\n",
              "\t<dt>$Gain</dt>\n",
              "\t\t<dd><style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4.19465357289869</li><li>3.71601344403117</li><li>3.71600565615802</li></ol>\n",
              "</dd>\n",
              "\t<dt>$SteadyStateProb</dt>\n",
              "\t\t<dd><table class=\"dataframe\">\n",
              "<caption>A matrix: 1 × 11 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>terror 0</th><th scope=col>terror 1</th><th scope=col>terror 2</th><th scope=col>terror 3</th><th scope=col>terror 4</th><th scope=col>terror 5</th><th scope=col>terror 6</th><th scope=col>terror 7</th><th scope=col>terror 8</th><th scope=col>terror 9</th><th scope=col>terror 10</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Probability</th><td>0.4174762</td><td>0.3357063</td><td>0.1799683</td><td>0.05125784</td><td>0.01240261</td><td>0.002608542</td><td>0.0004851836</td><td>8.088832e-05</td><td>1.221882e-05</td><td>1.687271e-06</td><td>2.041303e-07</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</dd>\n",
              "\t<dt>$Optimal_policy</dt>\n",
              "\t\t<dd><table class=\"dataframe\">\n",
              "<caption>A matrix: 1 × 11 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>terror 0</th><th scope=col>terror 1</th><th scope=col>terror 2</th><th scope=col>terror 3</th><th scope=col>terror 4</th><th scope=col>terror 5</th><th scope=col>terror 6</th><th scope=col>terror 7</th><th scope=col>terror 8</th><th scope=col>terror 9</th><th scope=col>terror 10</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Decision</th><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>2</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$Iteration\n:   3\n$PolicyChange\n:   \nA matrix: 4 × 11 of type dbl\n\n| terror 0 | terror 1 | terror 2 | terror 3 | terror 4 | terror 5 | terror 6 | terror 7 | terror 8 | terror 9 | terror 10 |\n|---|---|---|---|---|---|---|---|---|---|---|\n| 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n| 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 2 | 2 |\n| 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 |\n| 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 |\n\n\n$Gain\n:   1. 4.19465357289869\n2. 3.71601344403117\n3. 3.71600565615802\n\n\n\n$SteadyStateProb\n:   \nA matrix: 1 × 11 of type dbl\n\n| <!--/--> | terror 0 | terror 1 | terror 2 | terror 3 | terror 4 | terror 5 | terror 6 | terror 7 | terror 8 | terror 9 | terror 10 |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| Probability | 0.4174762 | 0.3357063 | 0.1799683 | 0.05125784 | 0.01240261 | 0.002608542 | 0.0004851836 | 8.088832e-05 | 1.221882e-05 | 1.687271e-06 | 2.041303e-07 |\n\n\n$Optimal_policy\n:   \nA matrix: 1 × 11 of type dbl\n\n| <!--/--> | terror 0 | terror 1 | terror 2 | terror 3 | terror 4 | terror 5 | terror 6 | terror 7 | terror 8 | terror 9 | terror 10 |\n|---|---|---|---|---|---|---|---|---|---|---|---|\n| Decision | 0 | 0 | 0 | 1 | 1 | 1 | 1 | 1 | 1 | 1 | 2 |\n\n\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$Iteration] 3\n\\item[\\$PolicyChange] A matrix: 4 × 11 of type dbl\n\\begin{tabular}{lllllllllll}\n terror 0 & terror 1 & terror 2 & terror 3 & terror 4 & terror 5 & terror 6 & terror 7 & terror 8 & terror 9 & terror 10\\\\\n\\hline\n\t 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n\t 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 2 & 2\\\\\n\t 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2\\\\\n\t 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2\\\\\n\\end{tabular}\n\n\\item[\\$Gain] \\begin{enumerate*}\n\\item 4.19465357289869\n\\item 3.71601344403117\n\\item 3.71600565615802\n\\end{enumerate*}\n\n\\item[\\$SteadyStateProb] A matrix: 1 × 11 of type dbl\n\\begin{tabular}{r|lllllllllll}\n  & terror 0 & terror 1 & terror 2 & terror 3 & terror 4 & terror 5 & terror 6 & terror 7 & terror 8 & terror 9 & terror 10\\\\\n\\hline\n\tProbability & 0.4174762 & 0.3357063 & 0.1799683 & 0.05125784 & 0.01240261 & 0.002608542 & 0.0004851836 & 8.088832e-05 & 1.221882e-05 & 1.687271e-06 & 2.041303e-07\\\\\n\\end{tabular}\n\n\\item[\\$Optimal\\_policy] A matrix: 1 × 11 of type dbl\n\\begin{tabular}{r|lllllllllll}\n  & terror 0 & terror 1 & terror 2 & terror 3 & terror 4 & terror 5 & terror 6 & terror 7 & terror 8 & terror 9 & terror 10\\\\\n\\hline\n\tDecision & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 2\\\\\n\\end{tabular}\n\n\\end{description}\n",
            "text/plain": [
              "$Iteration\n",
              "[1] 3\n",
              "\n",
              "$PolicyChange\n",
              "     terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6 terror 7\n",
              "[1,]        1        1        1        1        1        1        1        1\n",
              "[2,]        0        0        0        1        1        1        1        1\n",
              "[3,]        0        0        0        1        1        1        1        1\n",
              "[4,]        0        0        0        1        1        1        1        1\n",
              "     terror 8 terror 9 terror 10\n",
              "[1,]        1        1         1\n",
              "[2,]        1        2         2\n",
              "[3,]        1        1         2\n",
              "[4,]        1        1         2\n",
              "\n",
              "$Gain\n",
              "[1] 4.194654 3.716013 3.716006\n",
              "\n",
              "$SteadyStateProb\n",
              "             terror 0  terror 1  terror 2   terror 3   terror 4    terror 5\n",
              "Probability 0.4174762 0.3357063 0.1799683 0.05125784 0.01240261 0.002608542\n",
              "                terror 6     terror 7     terror 8     terror 9    terror 10\n",
              "Probability 0.0004851836 8.088832e-05 1.221882e-05 1.687271e-06 2.041303e-07\n",
              "\n",
              "$Optimal_policy\n",
              "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
              "Decision        0        0        0        1        1        1        1\n",
              "         terror 7 terror 8 terror 9 terror 10\n",
              "Decision        1        1        1         2\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# CTMC MDP model for rescue operational system!!!\n",
        "# For steady state prob for optimal policy\n",
        "prob <- function(opSet = policySet, t, lam, eps, mu) {\n",
        "  opTRM = matrix(0, nrow = t+1, ncol = t+1)\n",
        "  for (i in 2:t) {\n",
        "    opTRM[i, i-1] = sum(i*eps, opSet[i]*mu)\n",
        "    opTRM[i, i+1] = lam      \n",
        "  }\n",
        "  opTRM[1, 2] = lam\n",
        "  opTRM[t+1, t] = sum(t*eps, opSet[t+1]*mu)\n",
        "  \n",
        "  k = t+1\n",
        "  steady_prob <- matrix(0, nrow=1, ncol=k)\n",
        "  state <- matrix(0, nrow=1, ncol=k-1)\n",
        "  for (i in 1:(k-1)) {\n",
        "    if (i-2 < 0) {\n",
        "      state[i] <- (lam/opTRM[i+1,i])\n",
        "    } else {\n",
        "      state[i] <- state[i-1]*(lam/opTRM[i+1,i])\n",
        "    }\n",
        "  }\n",
        "  \n",
        "  steady_prob[1] <- (1+sum(state))^-1\n",
        "  for (i in 2:k) {\n",
        "    steady_prob[i] <- state[i-1]*steady_prob[1]\n",
        "  }\n",
        "  return(steady_prob)\n",
        "}\n",
        "\n",
        "# Check function to determine new policy is same with current or not \n",
        "checkPolicy = function(policySet, policySetnew) {\n",
        "  n = 0\n",
        "  for (i in policySet == policySetnew) {\n",
        "    if (i == 'FALSE') {\n",
        "      n = 1\n",
        "    } \n",
        "  } \n",
        "  if (n == 0) {\n",
        "    return(\"TRUE\")\n",
        "  } else {\n",
        "    return(\"FALSE\")\n",
        "  }\n",
        "} \n",
        "\n",
        "rewardR <- function(costR, RC, nr) {\n",
        "  if (RC == \"SR\") {\n",
        "    if (costR < 0) {\n",
        "      result = -sqrt(-costR * nr)      \n",
        "    } else {\n",
        "      result = sqrt(costR * nr)\n",
        "    }\n",
        "  } else if (RC == \"L\") {\n",
        "    result = costR * nr      \n",
        "  } else {\n",
        "    if (costR < 0) {\n",
        "      result = -(costR * nr)^2      \n",
        "    } else {\n",
        "      result = (costR * nr)^2      \n",
        "    }\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "\n",
        "rewardT <- function(costT, TC, nt) {\n",
        "  if (TC == \"SR\") {\n",
        "    if (costT < 0) {\n",
        "      result = -sqrt(-costT * nt)      \n",
        "    } else {\n",
        "      result = sqrt(costT * nt)\n",
        "    }\n",
        "  } else if (TC == \"L\") {\n",
        "    result = costT * nt      \n",
        "  } else {\n",
        "    if (costT < 0) {\n",
        "      result = -(costT * nt)^2      \n",
        "    } else {\n",
        "      result = (costT * nt)^2      \n",
        "    }\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "\n",
        "#########################################################\n",
        "#EDITS: 22ND FEB,2023\n",
        "#NEW SERVICE RATE STRUCTURE. ADD ORIGINAL ONE AS WELL\n",
        "probR = function(nr, nt, eps, mu, SR) {\n",
        "  #if (nt == 0 & nr == 0) {\n",
        "  if (nt == 0){\n",
        "    result = 0\n",
        "  } else {\n",
        "    if(SR=='ORG'){\n",
        "      result = nr*mu / (nr*mu + nt*eps)\n",
        "    }\n",
        "    else {\n",
        "    result = min(nr,nt)*mu / (min(nr,nt)*mu + nt*eps)\n",
        "  }\n",
        "  return(result)\n",
        "}\n",
        "}\n",
        "#########################################################\n",
        "\n",
        "# Define MDP function (for basic policy)\n",
        "MDP = function(lam, mu, eps, numRescue, numTerror, costR, costT, RC, TC, SR) {\n",
        "  r = numRescue\n",
        "  t = numTerror\n",
        "  # Design the three dimension matrix(i,j,k)\n",
        "  # k: Index of rescue team\n",
        "  # i: state(current)\n",
        "  # j: state(next)\n",
        "  \n",
        "  \n",
        "  #########################################################\n",
        "  #EDITS: 22ND FEB,2023\n",
        "  #NEW SERVICE RATES STRUCTURE, ADD ORIGINAL ONE AS WELL\n",
        "  aijMatrix = array(0, dim = c(t+1,t+1,r+1))\n",
        "\n",
        "for (i in 1:t){\n",
        "  for (k in 1:(r+1)){\n",
        "    if (k <= i){\n",
        "      aijMatrix[i,i+1,k] <- lam\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "for (i in 2:t){\n",
        "  for (k in 1:(r+1)){\n",
        "    if (k <= i){\n",
        "      if (SR=='ORG'){\n",
        "          aijMatrix[i,i-1,k] <- sum((k-1)*mu+(i-1)*eps)\n",
        "            }\n",
        "          else { \n",
        "        aijMatrix[i,i-1,k] <- sum(min(k-1,i-1)*mu+(i-1)*eps)        \n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  }\n",
        "\n",
        "\n",
        "for (k in 1:(r+1)){\n",
        "  if (k <= (t+1)){\n",
        "  if (SR=='ORG'){\n",
        "      aijMatrix[t+1,t,k] <- ((k-1)*mu+t*eps)\n",
        "    }\n",
        "    else {\n",
        "      aijMatrix[t+1,t,k] <- (min(k-1,t)*mu+t*eps)\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "for (i in 1:(t+1)) {\n",
        "    for (k in 1:(r+1)) {\n",
        "      if (k<=i){\n",
        "      aijMatrix[i,i,k] <- -sum(aijMatrix[i,,k])      \n",
        "    }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #########################################################\n",
        "  \n",
        "  #print(aijMatrix[4,4,5])\n",
        "  #cat('meu',mu)\n",
        "  #cat('epsilon',eps)\n",
        "  #break\n",
        "  \n",
        "  \n",
        "  # Design the MDP algorithm\n",
        "  # Value determination\n",
        "  policy = array(0, dim = c(1,t+1)) \n",
        "  policyOld = array(3, dim = c(1,t+1))\n",
        "  policyNew = array(1, dim=c(1,t+1)) # initially set all decision is 1 in first policy\n",
        "  policyTrack = array(2, dim=c(1,t+1))\n",
        "  iteration = 0\n",
        "  gainMatrix = c()\n",
        "  \n",
        "  while (checkPolicy(policyOld, policyNew) == 'FALSE') {\n",
        "    policyOld = policyNew\n",
        "    policy = policyNew\n",
        "    # Design the transition matrix regarding policy\n",
        "    A = array(0, dim = c(t+1,t+1))\n",
        "    for (i in 1:length(policy)) {\n",
        "      A[i,] = aijMatrix[i,,(policy[i])]  \n",
        "    }\n",
        "\n",
        "    # Design the cost matrix regarding policy\n",
        "    q = array(0, dim = c(t+1,1))\n",
        "    for (i in 1:length(policy)) {\n",
        "      cost = probR(nr=(policy[i]-1),nt=(i-1),eps,mu,SR)*rewardR(costR, RC, nr=(policy[i]-1))+\n",
        "        (1-probR(nr=(policy[i]-1),nt=(i-1),eps,mu,SR))*rewardT(costT, TC, nt=(i-1))\n",
        "      q[i,1] = cost\n",
        "    }\n",
        "    newA = cbind(array(1, dim=c(t+1,1)), -A[,1:t])\n",
        "    solution = solve(newA) %*% q\n",
        "    gain = solution[1] # First row of solution is gain value\n",
        "    gainMatrix = append(gainMatrix, gain)\n",
        "    \n",
        "    # Policy improvement\n",
        "    newsolution = array(0, dim=c(t+1,1))\n",
        "    for (i in 1:t) {\n",
        "      newsolution[i] = solution[i+1]\n",
        "    }\n",
        "    newsolution[t+1] = 0 # Set last v value as 0 to calcultate the test quantity in policy improvement\n",
        "    improveMatrix = array(0, dim=c(t+1,r+1))\n",
        "    for (i in 1:(t+1)) {\n",
        "      for (j in 1:(r+1)) {\n",
        "        if (j<=i){\n",
        "        # Cost when we have j rescue operation and i terrorists\n",
        "        cost = probR(nr=(j-1),nt=(i-1),eps,mu,SR)*rewardR(costR, RC, nr=(j-1))+\n",
        "          (1-probR(nr=(j-1),nt=(i-1),eps,mu,SR))*rewardT(costT, TC, nt=(i-1))\n",
        "        improveMatrix[i,j] = cost + aijMatrix[i,,j] %*% newsolution\n",
        "        }\n",
        "        else{improveMatrix[i,j] = 100000000000}\n",
        "      }\n",
        "    }  \n",
        "    \n",
        "    # pick the minimum value among the decision\n",
        "    policyNew = array(1, dim = c(1,t+1))\n",
        "    for (i in 1:length(policyNew)) {\n",
        "      policyNew[i] = which.min(improveMatrix[i,])\n",
        "    }\n",
        "    iteration = iteration + 1\n",
        "    policyTrack = rbind(policyTrack, policyNew)\n",
        "    policyNew\n",
        "  }\n",
        "  for (i in 1:length(policyNew)) {\n",
        "    policyNew[i] = policyNew[i] - 1\n",
        "  }\n",
        "  for (i in 1:nrow(policyTrack)) {\n",
        "    for (j in 1:ncol(policyTrack)) {\n",
        "      policyTrack[i,j] = policyTrack[i,j] - 1      \n",
        "    }\n",
        "\n",
        "  }\n",
        "  stateName = c()\n",
        "  for (i in 1:(t+1)) {\n",
        "    stateName = append(stateName, paste('terror',(i-1)))\n",
        "  }\n",
        "  Steady_prob = prob(opSet = policyNew, t, lam, eps, mu)  \n",
        "  colnames(policyTrack) = stateName\n",
        "  colnames(policyNew) = stateName\n",
        "  colnames(Steady_prob) = stateName\n",
        "  rownames(Steady_prob) = 'Probability'\n",
        "  rownames(policyNew) = 'Decision'\n",
        "  result <- list(\"Iteration\" = iteration,\n",
        "                 \"PolicyChange\" = policyTrack,\n",
        "                 \"Gain\" = gainMatrix,\n",
        "                 \"SteadyStateProb\" = Steady_prob,\n",
        "                 \"Optimal_policy\" = policyNew)\n",
        "  \n",
        "  return(result)\n",
        " \n",
        "}\n",
        "\n",
        "MDP(lam = 0.2763, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=5, costT=1, RC=\"QD\", TC=\"QD\",SR='UP')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A = MDP(lam = 0.3546, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=1, costT=1, RC=\"L\", TC=\"L\",SR='UP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # 1 more iteration for example plot\n",
        "# library(ggplot2)\n",
        "# result = MDP(lam = 0.2473, mu = 0.2829, eps = 0.1718, numRescue=3, numTerror=5, costR=1, costT=2, RC=\"L\", TC=\"L\",SR=\"UP\")\n",
        "# result = result$Gain\n",
        "# ddd = array(0, dim=c(5,2))\n",
        "# for (i in 1:5) {\n",
        "#   ddd[i,1] = i\n",
        "#   ddd[i,2] = result[i]  \n",
        "# }\n",
        "# ddd[5,1] = 5\n",
        "# ddd[5,2] = ddd[4,2]\n",
        "\n",
        "# ddd = as.data.frame(ddd)\n",
        "# ggplot(ddd, aes(x=V1, y=V2)) +\n",
        "#   geom_line(size=1) +\n",
        "#   labs(x = 'Number of iteration', y = 'Gain value',\n",
        "#        title = 'Gain value change during iterations')\n",
        "\n",
        "\n",
        "# # Experiment design\n",
        "# rescueSet = c(1,2,3,4,5,6,7,8,9,10)\n",
        "# gainResult = array(0, dim=c(5,length(rescueSet)))\n",
        "# for (j in 1:5) {\n",
        "#   for (i in 1:length(rescueSet)) {\n",
        "#     val = rescueSet[i]\n",
        "#     result = MDP(lam=0.2473, mu=0.2829, eps=0.1718, numRescue=val, numTerror=10, costR=1, costT=j, RC=\"L\", TC=\"L\",SR='UP')\n",
        "#     gainResult[j,i] = tail(result$Gain, 1)\n",
        "#   }  \n",
        "# }\n",
        "# gainResult = as.data.frame(t(gainResult))\n",
        "# gainResult$index = rescueSet\n",
        "# ggplot() +\n",
        "#   geom_line(data=gainResult, aes(x=index, y=V1, color='black'), size=1) +\n",
        "#   geom_line(data=gainResult, aes(x=index, y=V2, color='red'), size=1) +\n",
        "#   geom_line(data=gainResult, aes(x=index, y=V3, color='blue'), size=1) +\n",
        "#   geom_line(data=gainResult, aes(x=index, y=V4, color='purple'), size=1) +\n",
        "#   geom_line(data=gainResult, aes(x=index, y=V5, color='green'), size=1) +\n",
        "#   labs(x = 'Rescue forces capacity', y = 'Gain value of the system',\n",
        "#        title = 'Gain of the system over rescue team capacity') +\n",
        "#   scale_color_identity(name = \"Terror cost\",\n",
        "#                        labels = c(\"cost=1\", \"cost=2\", \"cost=3\", \"cost=4\", \"cost=5\"),\n",
        "#                        breaks = c(\"black\", \"red\", \"blue\", \"purple\", \"green\"),\n",
        "#                        guide = \"legend\")\n"
      ],
      "metadata": {
        "id": "SR5Lre6ptHj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (rc in list('SR','L','QD')) {\n",
        "  for (tc in list('SR','L','QD')) {\n",
        "    cat('(RC,TC): (',rc,',',tc,')','\\n\\n')\n",
        "    A = MDP(lam = 0.2763, mu = 0.2829, eps = 0.1718, numRescue=10, numTerror=10, costR=1, costT=2, RC=rc, TC=tc,SR='ORG')\n",
        "    print(A['Optimal_policy'])\n",
        "    cat('\\n\\n')\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jv3qZCcIkQw",
        "outputId": "371cdaf3-64c5-421c-f8c2-017a29f43796"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(RC,TC): ( SR , SR ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( SR , L ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( SR , QD ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( L , SR ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        2        3        3        3\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        4        4        4         4\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( L , L ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( L , QD ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( QD , SR ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        1        1        1        1        1\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        1        2        2         2\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( QD , L ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        2        2        2        3\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        3        3        3         3\n",
            "\n",
            "\n",
            "\n",
            "(RC,TC): ( QD , QD ) \n",
            "\n",
            "$Optimal_policy\n",
            "         terror 0 terror 1 terror 2 terror 3 terror 4 terror 5 terror 6\n",
            "Decision        0        1        2        3        4        5        6\n",
            "         terror 7 terror 8 terror 9 terror 10\n",
            "Decision        7        8        9        10\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Um1cqU16fPv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}